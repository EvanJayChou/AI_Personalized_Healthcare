{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cerebras.framework'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcerebras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cerebras.framework'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from cerebras.framework.tensorflow import compile\n",
    "\n",
    "model = load_model() # MODEL REQUIRED HERE\n",
    "cerebras_model = compile(model, mode=\"inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference Testing the X-Ray Vision Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import time\n",
    "\n",
    "def inference_request(request_json):\n",
    "    request = json.loads(request_json)\n",
    "    function_name = request[\"function\"]\n",
    "    params = request[\"params\"]\n",
    "\n",
    "    if function_name == \"predict\":\n",
    "        image_path = params[\"test_image_path\"]\n",
    "\n",
    "        img = load_img(image_path, target_size=(224,224))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        predictions = cerebras_model.predict(img_array)\n",
    "        predicted_output = np.argmax(predictions)\n",
    "\n",
    "        return {\"predicted_output\": int(predicted_output), \"confidence\": float(np.max(predictions))}\n",
    "    \n",
    "    else:\n",
    "        return {\"error\": f\"Function '{function_name}' not supported.\"}\n",
    "    \n",
    "request = json.dumps({\n",
    "    \"function\": \"predict\",\n",
    "    \"params\": {\n",
    "        \"test_image_path\": # NEED TO INSERT PATH HERE\n",
    "    }\n",
    "})\n",
    "response = inference_request(request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT is a conversational AI model that can be used in various ways to provide assistance, answer questions, and engage in discussions. Here are some of the best ways to use ChatGPT:\n",
      "\n",
      "1. **Language Learning:** ChatGPT can be used as a language learning tool. You can practice conversing in a new language with the model, and it will correct your grammar and pronunciation.\n",
      "2. **Writing Assistance:** ChatGPT can be used to generate ideas, proofread text, and even help with writing tasks such as creating outlines, introductions, and conclusions.\n",
      "3. **Research Assistance:** ChatGPT can be used to research topics, find relevant information, and summarize articles and books.\n",
      "4. **Personalized Recommendations:** ChatGPT can be used to get personalized recommendations for movies, books, music, and other forms of entertainment.\n",
      "5. **Language Translation:** ChatGPT can be used to translate text from one language to another in real-time.\n",
      "6. **Customer Service:** ChatGPT can be used as a chatbot to provide customer support and answer frequently asked questions.\n",
      "7. **Education:** ChatGPT can be used as a teaching tool to assist students with their studies, provide explanations of complex concepts, and offer feedback on assignments.\n",
      "8. **Creative Writing:** ChatGPT can be used as a prompt-generating tool to help with creative writing tasks such as writing stories, poems, and scripts.\n",
      "9. **Conversational Role-Playing:** ChatGPT can be used to engage in conversational role-playing exercises, such as practicing job interviews or medical consultations.\n",
      "10. **Brainstorming Sessions:** ChatGPT can be used to facilitate brainstorming sessions and help generate ideas for projects, business ventures, and other initiatives.\n",
      "11. **Summarizing Long Texts:** ChatGPT can be used to summarize long texts such as articles, books, and emails.\n",
      "12. **Chat Games:** ChatGPT can be used to play text-based games such as Hangman, Word Jumble, and 20 Questions.\n",
      "13. **Conversational Debates:** ChatGPT can be used to engage in conversational debates on various topics, from politics and history to science and technology.\n",
      "14. **Language Testing:** ChatGPT can be used to test language proficiency and identify areas for improvement.\n",
      "15. **Creative Problem-Solving:** ChatGPT can be used to help solve creative problems and provide novel solutions to complex challenges.\n",
      "\n",
      "To get the most out of ChatGPT, try the following:\n",
      "\n",
      "* Be clear and specific about what you need help with\n",
      "* Provide context and background information to help the model understand the topic\n",
      "* Ask follow-up questions to clarify any points that are unclear\n",
      "* Use conversational language to engage with the model\n",
      "* Experiment with different prompts and topics to see what works best for you\n",
      "\n",
      "Keep in mind that ChatGPT is a large language model, not a human, so it may make mistakes or not understand nuances of language. However, it can still be a valuable tool for providing assistance and engaging in conversations."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "import llm\n",
    "\n",
    "client = Cerebras(\n",
    "    api_key=os.environ.get(\"CEREBRAS_API_KEY\"),\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"SARS-CoV2 Protein Analysis\",\n",
    "            \"description\": \"Determine... TBD\",\n",
    "            \"parameters\":\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the best ways to use ChatGPT\",\n",
    "        }\n",
    "    ],\n",
    "    response = llm.chat.completions.create(\n",
    "        model=\"llama3.1-8b\",\n",
    "        tools = tools,\n",
    "        stream = True,\n",
    "    )\n",
    ")\n",
    "\n",
    "for chunk in chat_completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectiveness of continuous glucose monitoring in patient management of Type 2 Diabetes Mellitus: an umbrella review of systematic reviews from 2011 to 2024.\n",
      "Knockout of B2M in combination with PD-L1 overexpression protects MSC-derived new islet Î² cells from graft rejection in the treatment of canine diabetes mellitus.\n",
      "Novel cocktail therapy based on multifunctional supramolecular hydrogel targeting immune-angiogenesis-nerve network for enhanced diabetic wound healing.\n",
      "Sodium polystyrene sulfonate as an additional contributing factor to repeated gastric ulcers among other multiple factors in a patient undergoing hemodialysis: a case report.\n",
      "PET imaging of GABA<sub>A</sub> receptors in pancreatic islets by [<sup>11</sup>C]flumazenil.\n",
      "Elevated glucagon and postprandial hyperglycemia in fatty liver indicate early glucose intolerance in metabolic dysfunction associated steatotic liver disease.\n",
      "RNA-Puzzles Round V: blind predictions of 23 RNA structures.\n",
      "J-shaped association between serum glucose potassium ratio and prognosis in heart failure with preserved ejection fraction with stronger predictive value in non-diabetic patients.\n",
      "A few-shot diabetes foot ulcer image classification method based on deep ResNet and transfer learning.\n",
      "Correlation between admission hyperglycemia and postoperative pneumonia after hip fracture surgery: A propensity score-matched study.\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"echou6@go.pasadena.edu\"\n",
    "\n",
    "def get_pubmed(query, max_results = 100000):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"]\n",
    "\n",
    "def get_article(ids):\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(ids), retmode = \"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return records\n",
    "\n",
    "query = \"diabetes AND treatment\"\n",
    "pubmed_ids = get_pubmed(query, max_results = 100000)\n",
    "articles = get_article(pubmed_ids)\n",
    "\n",
    "count = 0\n",
    "for article in articles[\"PubmedArticle\"]:\n",
    "    print(article[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"])\n",
    "    count = count + 1\n",
    "    if (count == 10):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanc\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cerebras.framework'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaForCausalLM, LlamaTokenizer\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcerebras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CerebrasModel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cerebras.framework'"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from cerebras.framework.torch import CerebrasModel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "model_name = \"llama3.1-8b\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
